{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/soccer/database.sqlite\n","name":"stdout"}]},{"metadata":{"nbgrader":{"grade":false,"grade_id":"1","locked":true,"schema_version":1,"solution":false}},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:3.75vw;color:purple; font-style:bold\"><br>\nRegression Exercise Notebook\n</p><br>"},{"metadata":{"nbgrader":{"grade":false,"grade_id":"c2","locked":true,"schema_version":1,"solution":false}},"cell_type":"markdown","source":"# Exercise Notebook Instructions\n\n### 1. Important: Only modify the cells which instruct you to modify them - leave \"do not modify\" cells alone.  \n\nThe code which tests your responses assumes you have run the startup/read-only code exactly.\n\n### 2. Work through the notebook in order.\n\nSome of the steps depend on previous, so you'll want to move through the notebook in order.\n\n### 3. It is okay to use numpy libraries.\n\nYou may find some of these questions are fairly straightforward to answer using built-in numpy functions.  That's totally okay - part of the point of these exercises is to familiarize you with the commonly used numpy functions.\n\n### 4. Seek help if stuck\n\nIf you get stuck, don't worry!  You can either review the videos/notebooks from this week, ask in the course forums, or look to the solutions for the correct answer.  BUT, be careful about looking to the solutions too quickly.  Struggling to get the right answer is an important part of the learning process."},{"metadata":{"nbgrader":{"grade":false,"grade_id":"c3","locked":true,"schema_version":1,"solution":false},"trusted":true},"cell_type":"code","source":"# DO NOT MODIFY\n\n# import appropriate libraries\nimport sqlite3\nimport pandas as pd \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","execution_count":2,"outputs":[]},{"metadata":{"nbgrader":{"grade":false,"grade_id":"c2c","locked":true,"schema_version":1,"solution":false},"trusted":true},"cell_type":"code","source":"# DO NOT MODIFY\n\n# We will use the European Soccer dataset for this exercise.\n\ndef get_data():\n    cnx = sqlite3.connect('../input/soccer/database.sqlite')\n    df = pd.read_sql_query(\"SELECT * FROM Player_Attributes\", cnx)\n    return df\n\ndf = get_data()","execution_count":3,"outputs":[]},{"metadata":{"nbgrader":{"grade":false,"grade_id":"c445c","locked":true,"schema_version":1,"solution":false}},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:2.75vw;color:purple; font-style:bold\"><br>\n\nExercise 1: Drop NULLs in the Data<br><br></p>\n\n\nIn the cell below, modify the function `preparation`. The `preparation` function takes three arguments:\n* a dataframe, \n* a list of features, and \n* the name of regression target column.\n\nFunction should do the following: \n- to take the input data frame and remove all rows containing NULLs. \n- RETURN two data frames, one containing the feature columns and other the target column"},{"metadata":{"nbgrader":{"grade":false,"grade_id":"c555","locked":false,"schema_version":1,"solution":true},"trusted":true},"cell_type":"code","source":"# modify this cell\n\ndef preparation(dataf, features, target):\n    ### BEGIN SOLUTION\n    df = dataf.copy().dropna()\n    X = df[features]\n    y = df[target]\n    return X, y\n    ### END SOLUTION","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['potential', 'reactions', 'vision']\ntarget = ['overall_rating']\nX, y = preparation(df, features, target)\nX.shape, y.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"((180354, 3), (180354, 1))"},"metadata":{}}]},{"metadata":{"nbgrader":{"grade":true,"grade_id":"ex15","locked":true,"points":1,"schema_version":1,"solution":false},"trusted":true},"cell_type":"code","source":"# DO NOT MODIFY\nans1 = ['potential', 'reactions', 'vision']\nans2 = ['overall_rating']\n\ntry: \n    features = ans1\n    target   = ans2\n    X, y = preparation(df, features, target)\n    X.columns, y.columns\n    assert np.alltrue(X.columns.tolist() == ans1)\n    assert np.alltrue(y.columns.tolist() == ans2)\n    assert np.alltrue(X.shape[0] == 180354)\n    assert np.alltrue(y.shape[0] == 180354)\n\nexcept AssertionError as e: print(\"Try again, your output did not match the expected answer above\")","execution_count":6,"outputs":[]},{"metadata":{"nbgrader":{"grade":false,"grade_id":"cc445","locked":true,"schema_version":1,"solution":false}},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:2.75vw;color:purple; font-style:bold\"><br>\n\nExercise 2: Perform Splitting<br><br></p>\n\n\nIn the cell below, modify the function to take features (X) and target (y) dataframe and \nsplit 70% as training data and 30% as test data, using a random state = rstate.\n\nThe function should return X_train, X_test, y_train, and y_test"},{"metadata":{"nbgrader":{"grade":false,"grade_id":"5551","locked":false,"schema_version":1,"solution":true},"trusted":true},"cell_type":"code","source":"# modify this cell\n\ndef clean_data(X, y, rstate):\n    ### BEGIN SOLUTION\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rstate, test_size=0.3)\n    return X_train, X_test, y_train, y_test\n    ### END SOLUTION","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = clean_data(X, y, 9000)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"(126247, 3) (126247, 1)\n(54107, 3) (54107, 1)\n","name":"stdout"}]},{"metadata":{"nbgrader":{"grade":true,"grade_id":"ex151","locked":true,"points":1,"schema_version":1,"solution":false},"trusted":true},"cell_type":"code","source":"# DO NOT MODIFY\n\ntry: \n    X_train, X_test, y_train, y_test = clean_data(X, y, 9000)\n\n    assert np.alltrue(X_train.shape == (126247, 3))\n    assert np.alltrue(y_train.shape == (126247, 1))\n    assert np.alltrue(X_test.shape == (54107, 3))\n    assert np.alltrue(y_test.shape == (54107, 1))\n\nexcept AssertionError as e: print(\"Try again\")","execution_count":11,"outputs":[]},{"metadata":{"nbgrader":{"grade":false,"grade_id":"cv445","locked":true,"schema_version":1,"solution":false}},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:2.75vw;color:purple; font-style:bold\"><br>\n\nExercise 3: Build a Regressor<br><br></p>\n\nIn the cell below, modify the function to take X_train, y_train only and RETURN a regressor\nfor predicting the y_train based on columns in X_train. You can pick any regressor model.\n\nThe function should RETURN a trained model. We will test your regressor on X_test and y_test"},{"metadata":{"nbgrader":{"grade":false,"grade_id":"c5553","locked":false,"schema_version":1,"solution":true},"trusted":true},"cell_type":"code","source":"# modify this cell\n\ndef train_regressor(X_train, y_train):\n    ### BEGIN SOLUTION\n    reg = LinearRegression()\n    reg.fit(X_train, y_train)\n    return reg\n    ### END SOLUTION","execution_count":16,"outputs":[]},{"metadata":{"nbgrader":{"grade":true,"grade_id":"ex153","locked":true,"points":1,"schema_version":1,"solution":false},"trusted":true},"cell_type":"code","source":"# DO NOT MODIFY\n\nthreshold = 4.5\n\ntry: \n    model = train_regressor(X_train, y_train['overall_rating'])\n    y_prediction = model.predict(X_test)\n    rmse = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n    #print(rmse)\n    assert np.alltrue(rmse < threshold)\nexcept AssertionError as e: print(\"Keep trying - can you get an RMSE < %f\" % threshold)","execution_count":15,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"fit() got an unexpected keyword argument 'X_train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-d9ad9197cc90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_regressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overall_rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-8c727aa907b7>\u001b[0m in \u001b[0;36mtrain_regressor\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m### BEGIN SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m### END SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'X_train'"]}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}